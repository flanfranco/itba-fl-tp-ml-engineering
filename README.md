# Trabajo PrÃ¡ctico Final
### ML Engineering

Bienvenido al TP Final de la [Diplomatura en Cloud Data Engineering del ITBA](https://innovacion.itba.edu.ar/educacion-ejecutiva/tic/cloud-data-engineering/).

### DescripciÃ³n del requerimiento:

Se solicita crear un DAG de Airflow que actÃºe de ETL utilizando el dataset de [demoras y cancelaciones de viajes aÃ©reos](https://www.kaggle.com/datasets/yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018) siguiendo los [requerimientos detallados por la cÃ¡tedra](https://github.com/flanfranco/itba-fl-tp-ml-engineering/blob/main/docs/%5BRFC%5D%20Trabajo%20Pr%C3%A1ctico%20Final.pdf).

### Objetivo:

Poner en prÃ¡ctica los conocimientos adquiridos a lo largo del cursado de la [diplomatura](https://innovacion.itba.edu.ar/educacion-ejecutiva/tic/cloud-data-engineering/): 

* MÃ³dulo 1: AWS Cloud Architecture
* MÃ³dulo 2: Python Data Applications
* MÃ³dulo 3: Machine Learning Engineering


## ResoluciÃ³n

### DescripciÃ³n

Se propone resolver los [requerimientos](https://github.com/flanfranco/itba-fl-tp-ml-engineering/blob/main/docs/%5BRFC%5D%20Trabajo%20Pr%C3%A1ctico%20Final.pdf) implementando una arquitectura del tipo [lake house](https://aws.amazon.com/blogs/big-data/build-a-lake-house-architecture-on-aws/) en AWS. Para tal fin se van a utilizar los siguientes servicios:
* MWAA (Amazon Managed Workflows for Apache Airflow) para orquestar la ejecuciÃ³n de las tareas de extracciÃ³n, transformaciÃ³n y carga de datos (ETL).
* S3 como datalake
* Glue para procesar y transformar los datos.
* Glue Data Catalog como catÃ¡logo de datos de la soluciÃ³n.
* Redshift Spectrum como DW con la posibilidad de consumir tablas "externas" del datalake (lake house).
* QuickSight para exponer de manera visual los datos procesados.
* Athena para poder analizar tablas del datalake.
* IAM para gestionar los roles y permisos relacionados a los servicios enunciados.
* VPC y servicios relacionados para poder desplegar todo el newtorking de la soluciÃ³n.

La soluciÃ³n tiene el objetivo de poner en prÃ¡ctica (de manera introductoria) el despligue en AWS de una arquitectura productiva de procesamiento de datos moderna, escalable, robusta y segura, mostrando: 

* la utilizaciÃ³n de un datalake como repositorio de datos escalable
* la utilizaciÃ³n de spark para procesar grandes volÃºmenes de datos
* la posibilidad de combinar tablas de un schema de DW agregadas con tablas externas (del datalake) al mÃ¡ximo nivel de detalle.

Notas: Es necesario tener en cuenta la variable costo ya que en un despligue productivo real serÃ­a conveniente analizar en detalle:
* implementar Airflow en EKS, en vez de MWAA. Analizando tiempo y recursos asociados a mantener en EKS el ambiente de Airflow con alta disponibilidad, auto escalado, etc... (como lo ofrece MWAA) 
* utilizar EMR, en vez de Glue


### Arquitectura

![Image of the data architecture](https://raw.githubusercontent.com/flanfranco/itba-fl-tp-ml-engineering/main/docs/img/01_aws_architecture.png) 

La arquitectura principalmente expone:
* el despliegue del ambiente de MWAA [creando una VPC y sus componentes](https://docs.aws.amazon.com/mwaa/latest/userguide/vpc-create.html#vpc-create-template-private-or-public) a travÃ©s de un [stack de CloudFormation](https://docs.aws.amazon.com/mwaa/latest/userguide/samples/cfn-vpc-public-private.zip) proporcionado por AWS.
* el despligue de una subnet group en las subnets privadas de la VPC anteriormente creada.
* el despliegue de un cluster de Redshift en la subnet group anteriormente creada.
* el despligue de un Gateway Endpoint para comunicar Redshift con S3 de manera privada.

### Flujo de procesamiento de datos

A continuaciÃ³n se presenta el flujo del procesamiento de datos basado en la ejecuciÃ³n del [DAG desarrollado](https://github.com/flanfranco/itba-fl-tp-ml-engineering/blob/main/aws-deploy/mwaa/dags/aws_etl_dag.py):

![Image of the data flow](https://raw.githubusercontent.com/flanfranco/itba-fl-tp-ml-engineering/main/docs/img/02_flow.png) 

![Image of the airflow dag](https://raw.githubusercontent.com/flanfranco/itba-fl-tp-ml-engineering/main/docs/img/03_airflow_aws_etl_dag.png) 

A continuaciÃ³n se detalla la estructura de buckets desplegada:

![Image of buckets](https://raw.githubusercontent.com/flanfranco/itba-fl-tp-ml-engineering/main/docs/img/07_s3_buckets.png) 

* itbafl-**airflow**-useast1-232483837258-prd: bucket correspondiente al despliegue del ambiente de MWAA. El mismo almacena los dags, plugins y requirements con configuraciones.
* itbafl-**raw**-useast1-232483837258-prd: bucket del datalake correspondiente a almacenar los datos en su formato original (csv, json, etc.) para luego ser procesados.
* itbafl-**stage**-useast1-232483837258-prd: bucket del datalake correspondiente a almacenar en formato parquet (y con particionado) los datos originales transformados y procesados con lÃ³gica de negocio (aplicando filtros, joins, etc.).
* itbafl-**analytics**-useast1-232483837258-prd: bucket del datalake correspondiente a almacenar en formato parquet (y con particionado) datos agregados y depurados para que sean consumidos por usuarios de anÃ¡lisis o para su posterior carga en el DW.
* itbafl-**reports**-useast1-232483837258-prd: bucket correspondiente al almacenamiento de reportes generados como resultado de la ejecuciÃ³n de los dags de procesamiento de datos.
* itbafl-**scripts**-useast1-232483837258-prd: bucket donde se almacenan los scripts correspondientes a los servicios de procesamientos de datos utilizados en la arquitectura desplegada. En este caso los scripts de pyspark (AWS Glue).
* itbafl-**logs**-useast1-232483837258-prd: bucket donde se depositan los logs resultantes de los servicios de procesamientos de datos utilizados en la arquitectura desplegada.
* itbafl-**temp**-useast1-232483837258-prd: bucket donde se depositan temporalmente los resultados de la utilizaciÃ³n de los servicios de la arquitectura desplegada, como por ejemplo las queries resultantes de Athena, o los parquets temporales resultantes de utilizar [AWS Data Wrangler](https://github.com/awslabs/aws-data-wrangler).

En referencia a los **scripts de pyspark** responsables de transformar los datos a travÃ©s de la ejecuciÃ³n de tareas de Glue es importante remarcar:

* Script [raw --> stage](https://github.com/flanfranco/itba-fl-tp-ml-engineering/blob/main/aws-deploy/scripts/glue/raw_to_stage_us_flights_airline_delay_cancellation.py):
- recibe como parÃ¡metro el aÃ±o de procesamiento (ptn_year).
- en base al mismo realiza un push_down_predicate filtrando solo lo relacionado a ese aÃ±o en la data fuente (raw).
- tiene configurado "spark.conf.set("spark.sql.sources.partitionOverwriteMode","dynamic")" para poder "pisar" particiones preexistentes.  
- almacena los datos en parquet particionados por ptn_year.

* Script [stage --> analytics](https://github.com/flanfranco/itba-fl-tp-ml-engineering/blob/main/aws-deploy/scripts/glue/stage_to_analytics_agg_flights_delay_by_date_airport.py):
- recibe como parÃ¡metro el aÃ±o de procesamiento (ptn_year).
- en base al mismo realiza un push_down_predicate filtrando solo lo relacionado a ese aÃ±o en la data input (stage).
- tiene configurado "spark.conf.set("spark.sql.sources.partitionOverwriteMode","dynamic")" para poder "pisar" particiones preexistentes.  
- aplica lÃ³gica de negocio para filtrar vuelos que no han sido cancelados y que tengan valor en los campos fl_date, origin y dep_delay.
- aplica una agregaciÃ³n por fl_date y origin.
- suma 2 campos (aÃ±o y mes) y renombra columnas.
- almacena los datos en parquet particionados por flight_year, flight_month, y flight_date.

En referencia a la tarea [process_anomaly_detection](https://github.com/flanfranco/itba-fl-tp-ml-engineering/blob/bd350a8a67e0ab906a69b084ae0c4d8a9320bed1/aws-deploy/mwaa/dags/aws_etl_dag.py#L9) perteneciente al [dag aws_etl_dag](https://github.com/flanfranco/itba-fl-tp-ml-engineering/blob/main/aws-deploy/mwaa/dags/aws_etl_dag.py) la misma consta de 4 partes importantes:
* La primera parte se encarga de leer los datos correspondientes a la fuente previamente agregada para el aÃ±o ejecutado en la recarga. Para esto se utiliza el mÃ©todo s3.read_parquet de la librerÃ­a awswrangler.
* La segunda parte es la encargada de aplicar el algoritmo de detecciÃ³n de anomalias (sklearn --> Isolation Forest) y generar un dataframe con el cÃ¡lculo del modelo para cada aeropuerto.
* La tercera parte es la encargada de persistir ese dataframe en el DW utilizando nuevamente la librerÃ­a awswrangler pero ahora con el mÃ©todo wr.redshift.copy que lo que hace es generar en el bucket temporal un archivo parquet y persistirlo con el comando COPY en el DW. Esta inserciÃ³n el DW se trabaja con el modo "upsert" para no generar duplicados ante un reprocesamiento.
* La Ãºltima parte es la encargada de generar los reportes por aeropuerto y almacenarlos en el bucket de reportes.

Nota: SerÃ­a conveniente utilizar Airflow solamente como orquestador y no como procesamiento. En base a esto en una prÃ³xima iteraciÃ³n serÃ­a recomendable llevar el procesamiento del Modelo de ML a SageMaker o ECS/EKS, y abrir las otras partes en otras tareas.


### Reportes de ejemplo

A continuaciÃ³n se muestran algunas capturas correspondientes a los reportes generados por el dag. En algunos casos pueden denotarse rÃ¡pidamente faltante de datos (raw) (julio 2011 y octubre 2009 por ej.):

![Image of 2009 report](https://raw.githubusercontent.com/flanfranco/itba-fl-tp-ml-engineering/main/aws-deploy/reports_example/2009_CSG_anual_report.png) 

![Image of 2011 report](https://raw.githubusercontent.com/flanfranco/itba-fl-tp-ml-engineering/main/aws-deploy/reports_example/2011_LAX_anual_report.png) 

![Image of 2014 report](https://raw.githubusercontent.com/flanfranco/itba-fl-tp-ml-engineering/main/aws-deploy/reports_example/2014_DAL_anual_report.png) 

![Image of 2018 report](https://raw.githubusercontent.com/flanfranco/itba-fl-tp-ml-engineering/main/aws-deploy/reports_example/2018_ABE_anual_report.png) 


### Dashboard QuickSight

A continuaciÃ³n se muestran capturas del dashboard bÃ¡sico de QuickSight diseÃ±ado que busca exponer la utilizaciÃ³n conjunta de datos agregados provenientes del DW junto a datos con mÃ¡ximo nivel de detalle provenientes del datalake (stage).

![Image of quicksight](https://raw.githubusercontent.com/flanfranco/itba-fl-tp-ml-engineering/main/docs/img/08_quicksight_dashboard.png) 

En la configuraciÃ³n del dataset de QuickSight puede verse la [query](https://github.com/flanfranco/itba-fl-tp-ml-engineering/blob/main/aws-deploy/scripts/redshift/dw_spectrum_quicksight_query.sql) utilizada para integrar el datalake con el dw de la siguiente manera:

![Image of quicksight datasource](https://raw.githubusercontent.com/flanfranco/itba-fl-tp-ml-engineering/main/docs/img/09_quicksight_datasource.png) 


### Detalle del despliegue

Antes es importante remarcar que la etapa de desarrollo de la soluciÃ³n se realizÃ³ en Ubuntu, configurando AWS CLI con un usuario con permisos y levantando un ambiente de airflow de desarrollo/test con docker-compose. Luego, una vez validada la solucion, se levantÃ³ el ambiente de MWAA y se desplegÃ³ el dag desarrollado en el mismo. 

A continuaciÃ³n se detallan los pasos necesarios para replicar la soluciÃ³n implementada:

1) CreaciÃ³n de la estructura de buckets en S3 segÃºn lo comentado anteriormente en esta guÃ­a.

En el bucket itbafl-airflow-useast1-232483837258-prd se desplegaron los [archivos compartidos](https://github.com/flanfranco/itba-fl-tp-ml-engineering/tree/main/aws-deploy/mwaa).

En el bucket itbafl-raw-useast1-232483837258-prd se organizaron los archivos fuente csv con el esquema de folders year=yyyy. Esto es para que luego se pueda ejecutar en la tarea raw --> stage el push_down_predicate sobre la particiÃ³n year.

2) Despliegue del ambiente de MWAA [creando una VPC y sus componentes](https://docs.aws.amazon.com/mwaa/latest/userguide/vpc-create.html#vpc-create-template-private-or-public) a travÃ©s de un [stack de CloudFormation](https://docs.aws.amazon.com/mwaa/latest/userguide/samples/cfn-vpc-public-private.zip) proporcionado por AWS.

Nota: el "web server access" se configurÃ³ como Public network pero en caso de un despliegue formal deberÃ­a optarse por private.

3) IAM Roles:
- Se modificÃ³ el role "AmazonMWAA-itbafl-airflow-environment-xxxxxx" agregÃ¡ndole los siguientes permisos: AmazonS3FullAccess, AWSGlueConsoleFullAccess, AmazonSageMakerFullAccess (para probar scripts spark con glue notebook de sagemaker).
- Se creÃ³ el role "AWSGlueServiceRoleDefault" agregÃ¡ndole los siguientes permisos: AmazonS3FullAccess, AWSGlueServiceRole.
- Se creÃ³ el role "AWSRedshiftServiceRoleDefault" agregÃ¡ndole los siguientes permisos: AmazonS3FullAccess, AWSGlueConsoleFullAccess.
4) Glue:
- En la secciÃ³n Databases se crearon: raw, stage y analytics.
- Se crearon 3 crawlers ejecutando los estos [scripts](https://github.com/flanfranco/itba-fl-tp-ml-engineering/tree/main/aws-deploy/scripts/glue/crawlers) en CloudShell. 
- Se crearon 2 jobs de tipo spark (Glue Version 2 - Worker type G.1X - y Maximum capacity 2) donde:

-- raw_to_stage_us_flights_airline_delay_cancellation --> Script location: s3://itbafl-scripts-useast1-232483837258-prd/glue/raw_to_stage_us_flights_airline_delay_cancellation.py

-- stage_to_analytics_agg_flights_delay_by_date_airport --> Script location: s3://itbafl-scripts-useast1-232483837258-prd/glue/stage_to_analytics_agg_flights_delay_by_date_airport.py

Ambos tienen Job parameters --ptn_year.


Redshift

Quicksight
Se creÃ³ un Security Group siguiendo las [indicaciones](https://docs.aws.amazon.com/quicksight/latest/user/enabling-access-redshift.html) y luego se lo asociÃ³ al Cluster de Redshift.


ğŸ‘¨ğŸ½â€ğŸ’» Flavio Lanfranco
